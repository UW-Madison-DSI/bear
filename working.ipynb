{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP author search with OpenAlex data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal is to return at author (and institution level) from a given search query.\n",
    "\n",
    "### Groupby and aggregate\n",
    "\n",
    "Borrowing/Stealing? the design language from pandas, let's think about `groupby` and `aggregate`.\n",
    "\n",
    "- groupby: defines the return object level (`author` for now)\n",
    "- aggregate: what formula we will use to `reduce` multiple records into a single metric. For example:\n",
    "    - basic count of hits\n",
    "    - custom `reranker` borrowing from retrival augmented generation (RAG) field, we weights the things that people like to see to obtain a score. More specifically, we can obtain the `cited_by_count` in each relevant paper and sum all within an author.\n",
    "    - `reranker` can also sources form multiple underlying metrics like what we do in [faculty search](https://github.com/UW-Madison-DSI/faculty-search/blob/eff2ecfedcf5e817e70e3f3541b91d4cceeabb27/api/core.py#L387)\n",
    "\n",
    "TODOs:\n",
    "\n",
    "1. Make a MVP groupby aggregate interface for search with base hit counts\n",
    "1. Implement faculty search `reranker` into aggregate\n",
    "\n",
    "\n",
    "Mock Interface \n",
    "\n",
    "```python\n",
    "search_results = search(\"effect of fungicide on corn\")\n",
    "search_results.groupby(\"author\").aggregate(\"count\")  # Hit Counts, return authors\n",
    "search_results.groupby(\"author\").aggregate(\"reranker_v0\")  # Fully custom reranker, return author\n",
    "search_results.groupby(\"institution\").aggregate(\"count\")  # Hit Counts, return institute\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what we have now, without pulling a lot of author data, we should make reranker_v0 as follow:\n",
    "\n",
    "1. Get a list of relevant articles w.r.t. search query\n",
    "2. group by author\n",
    "3. weight by sum of similarity\n",
    "\n",
    "This will be significantly better than the vanilla count without putting too much work into it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openalex_search.search import _search, SearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = _search(\"climate change\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchResults.from_raw(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openalex_search import search\n",
    "\n",
    "search(\"Higgs field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlmodel import SQLModel\n",
    "from pathlib import Path\n",
    "from openalex_search.db import init, ENGINE\n",
    "from openalex_search.ingest import ingest\n",
    "\n",
    "SQLModel.metadata.drop_all(ENGINE)\n",
    "init()\n",
    "# ingest(Path(\"local_data/test_authors.parquet\"))\n",
    "# ingest(Path(\"local_data/test_articles.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlmodel import Session, text, Index\n",
    "from openalex_search.db import ENGINE, Work\n",
    "from openalex_search.common import CONFIG\n",
    "\n",
    "with Session(ENGINE) as session:\n",
    "    session.connection().execute(text(\"DROP INDEX IF EXISTS work_index;\"))\n",
    "    session.commit()\n",
    "\n",
    "index = Index(\n",
    "    \"work_index\",\n",
    "    Work.embedding,\n",
    "    postgresql_using=\"hnsw\",\n",
    "    postgresql_with={\n",
    "        \"m\": CONFIG.HNSW_M,\n",
    "        \"ef_construction\": CONFIG.HNSW_EF_CONSTRUCTION,\n",
    "    },\n",
    "    postgresql_ops={\"embedding\": \"vector_ip_ops\"},\n",
    ")\n",
    "index.create(bind=ENGINE, checkfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"local_data/uw-works-27-last.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
