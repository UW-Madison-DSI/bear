{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Backend for Embedded Academic Resources (BEAR)","text":"<p>Open-source framework for semantic expert search, digital twin interactions, and easy academic data integration.</p>"},{"location":"#why-bear","title":"Why BEAR?","text":"<p>Finding experts is slow and fragmented. BEAR solves this with:</p> <ul> <li>Semantic search using plain language to find domain experts.</li> <li>Digital twins \u2013 AI-powered avatars built from an expert\u2019s papers, talks, and datasets, enabling chat with their work for early engagement.</li> <li>One-click deployment for universities.</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Quick Setup: Launch a proof-of-concept in minutes.</li> <li>Semantic Search: Plain language search with advanced embeddings, at resource or author level.</li> <li>Digital Twins: Chat with papers or expert-like avatars.</li> <li>AI Profiles: Auto-generated author profiles.</li> <li>Custom Data Integration: Integrate with your institution's internal data, or other data source.</li> </ul>"},{"location":"#value","title":"Value","text":"<ul> <li>Makes academic data accessible and conversational.</li> <li>Accelerates collaboration and discovery.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>See Getting Started.</p>"},{"location":"api_usage/","title":"API Usage","text":"In\u00a0[\u00a0]: Copied! <pre>import httpx\n\nresponse = httpx.get(\"http://localhost:8000\")\nresponse.json()\n</pre> import httpx  response = httpx.get(\"http://localhost:8000\") response.json() Out[\u00a0]: <pre>{'Instruction': 'Try /search_resource?query=your_query_here&amp;top_k=3 or /search_author?query=your_query_here&amp;top_k=3'}</pre> In\u00a0[5]: Copied! <pre>response = httpx.get(\"http://localhost:8000/search_resource?query=corn&amp;top_k=100&amp;since_year=2020\")\nresponse.json()[0]\n</pre> response = httpx.get(\"http://localhost:8000/search_resource?query=corn\u22a4_k=100&amp;since_year=2020\") response.json()[0] Out[5]: <pre>{'id': 'https://openalex.org/W4394334905',\n 'doi': 'https://doi.org/10.6084/m9.figshare.14306485',\n 'title': 'Effects of corn processing on piglet performance and intestinal parameters',\n 'display_name': 'Effects of corn processing on piglet performance and intestinal parameters',\n 'publication_year': 2021,\n 'publication_date': '2021-01-01',\n 'type': 'dataset',\n 'cited_by_count': 0,\n 'source_display_name': 'Figshare',\n 'topics': ['Animal Nutrition and Physiology',\n  'Animal Behavior and Welfare Studies',\n  'Effects of Environmental Stressors on Livestock'],\n 'abstract': 'ABSTRACT The objective of the present study was to compare the effects of corn processing on performance and intestinal parameters of weanling piglets. To accomplish our goal, 42 piglets (21 days-old, 7.18\u00b11.0 kg body weight) were randomly allocated (seven pens/treatment; three pigs/pen) to one of two treatments: ground corn \u2013 corn ground through a hammer mill with a 1.0-mm screen after being ground by a hammer mill with a 3.0-mm screen, and extruded corn \u2013 corn was wet extruded after being ground by a hammer mill with a 2.0-mm screen and, after extrusion, it was ground by a hammer mill with a 1.0-mm screen. In both methods, corn from the same batch was used. Results were considered statistically significant when P&amp;lt;0.05 and a tendency when P&amp;lt;0.10. Analyses were performed using the GLIMMIX procedure of SAS. Pigs fed ground or extruded corn diet had similar growth performance. Duodenum and jejunum of pigs fed extruded corn had greater villus height compared with those of pigs fed ground corn. Crypt depth was not influenced by corn processing. Duodenum and jejunum of pigs fed extruded corn had greater villus:crypt ratio compared with those of pigs fed ground corn. In the duodenum, the expression of zonula occludens-1 (ZO-1) was greater, and the expression of Occludin-1 tended to be greater in pigs fed the extruded corn diets. There was no effect of corn processing on ZO-1 and Occludin-1 expression in the jejunum, nor TGF-\u03b21 expression in duodenum and jejunum. There was no effect of the type of corn processing on colonic total bacteria or Enterobacteriaceae and Lactobacillus abundance. Piglets fed diets with ground corn or extruded corn have similar growth performance. However, piglets fed diets with extruded corn present improved intestinal morphology and tight junction protein expression compared with those fed ground corn.',\n 'distance': 0.8217573165893555,\n 'author_ids': ['https://openalex.org/A5024349832',\n  'https://openalex.org/A5061739467',\n  'https://openalex.org/A5016723638',\n  'https://openalex.org/A5033796171',\n  'https://openalex.org/A5076938613',\n  'https://openalex.org/A5034497487',\n  'https://openalex.org/A5073919022',\n  'https://openalex.org/A5083699987',\n  'https://openalex.org/A5089073970']}</pre> In\u00a0[8]: Copied! <pre>response = httpx.get(\"http://localhost:8000/search_author?query=corn&amp;top_k=100&amp;since_year=2020\")\nresponse.json()[:3]\n</pre> response = httpx.get(\"http://localhost:8000/search_author?query=corn\u22a4_k=100&amp;since_year=2020\") response.json()[:3] Out[8]: <pre>[{'author_id': 'https://openalex.org/A5055080030', 'score': 8.709359288215637},\n {'author_id': 'https://openalex.org/A5036071829', 'score': 7.923681020736694},\n {'author_id': 'https://openalex.org/A5061081209', 'score': 4.839542508125305}]</pre>"},{"location":"api_usage/#api-usage","title":"API Usage\u00b6","text":"<p>The BEAR API is the primary developer-facing tool of our project. It is built with FastAPI, focusing on simplicity and core use cases:</p> <ul> <li>Search Resource \u2013 Hybrid search</li> <li>Search Author \u2013 Hybrid search with a cluster (<code>group-by</code>) reranker (<code>aggregate</code>)</li> <li>Chat with Resource \u2013 Planned (not yet implemented)</li> <li>Chat with Author \u2013 Planned (not yet implemented)</li> </ul>"},{"location":"api_usage/#search-resource","title":"Search Resource\u00b6","text":""},{"location":"api_usage/#search-person","title":"Search Person\u00b6","text":""},{"location":"getting_started/","title":"Getting Started","text":"<p>BEAR is built for easy institutional deployment. Use this guide to quickly set up a proof-of-concept for semantic search and expert discovery at your university.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Git</li> <li>Docker and Docker Compose</li> </ul>"},{"location":"getting_started/#installation","title":"Installation","text":""},{"location":"getting_started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/uw-madison-dsi/bear.git\ncd bear\n</code></pre>"},{"location":"getting_started/#2-install-dependencies","title":"2. Install Dependencies","text":"<p>BEAR uses uv for dependency management:</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\nuv sync\n</code></pre>"},{"location":"getting_started/#3-configuration","title":"3. Configuration","text":"<p>Copy the example environment file and configure your institutional settings:</p> <pre><code>cp example.env .env\n</code></pre> <p>Edit the <code>.env</code> file with your specific configuration. Key settings include:</p> <ul> <li>Institution identifier (OpenAlex format)</li> <li>Embedding model preferences</li> <li>Custom data source configurations</li> <li>API keys for external services</li> </ul> <p>See the Config Reference for detailed configuration options.</p>"},{"location":"getting_started/#4-start-backend","title":"4. Start Backend","text":"<pre><code>docker compose up -d\n</code></pre> <p>This will start:</p> <ul> <li>API service: http://localhost:8000</li> <li>attu GUI for Milvus: http://localhost:3000</li> <li>Milvus vector database:</li> <li>Endpoint: http://localhost:19530</li> <li>Diagnostic Web-UI: http://localhost:9091/webui/</li> <li>MinIO (internal service)</li> <li>etcd (internal service)</li> </ul>"},{"location":"getting_started/#5-crawl-academic-data","title":"5. Crawl Academic Data","text":"<p>Crawl data from OpenAlex for your institution:</p> <pre><code>uv run bear/crawler.py &lt;your-institution-name&gt;\n</code></pre> <p>For example, for University of Wisconsin-Madison:</p> <pre><code>uv run bear/crawler.py uw-madison\n</code></pre>"},{"location":"getting_started/#6-ingest-data","title":"6. Ingest Data","text":"<p>Process and vectorize the crawled data:</p> <pre><code># Test run first\nuv run bear/ingest.py --test\n\n# Full ingest\nuv run bear/ingest.py\n</code></pre> <p>The API will be available at <code>http://localhost:8000</code>.</p>"},{"location":"getting_started/#testing-the-installation","title":"Testing the Installation","text":"<p>Test your installation with a sample API call:</p> <pre><code>curl \"http://localhost:8000/search_author?query=data%20science\"\n</code></pre>"},{"location":"getting_started/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Usage for hands-on examples</li> </ul>"},{"location":"examples/embedder/","title":"Embedder","text":"In\u00a0[1]: Copied! <pre>from bear.embedding import get_embedder\nfrom bear.config import config, EmbeddingConfig\n</pre> from bear.embedding import get_embedder from bear.config import config, EmbeddingConfig In\u00a0[9]: Copied! <pre>%%time\n# Get default embedder based on the configuration\nembedder = get_embedder(config.embedding_config)\nprint(embedder.info)\n\n# Use the embedder to embed a document\nvectors = embedder.embed(text=[\"This is a test document.\", \"This is another sentence.\"], text_type=\"doc\")\nprint(f\"Document 1 vectors: {vectors[0][:3]}...\")\nprint(f\"Document 2 vectors: {vectors[1][:3]}...\")\n</pre> %%time # Get default embedder based on the configuration embedder = get_embedder(config.embedding_config) print(embedder.info)  # Use the embedder to embed a document vectors = embedder.embed(text=[\"This is a test document.\", \"This is another sentence.\"], text_type=\"doc\") print(f\"Document 1 vectors: {vectors[0][:3]}...\") print(f\"Document 2 vectors: {vectors[1][:3]}...\") <pre>2025-07-23 19:40:32,218 - httpx - INFO - HTTP Request: GET http://olvi-1:8000/info \"HTTP/1.1 200 OK\"\n2025-07-23 19:40:32,237 - httpx - INFO - HTTP Request: POST http://olvi-1:8000/embeddings \"HTTP/1.1 200 OK\"\n2025-07-23 19:40:32,248 - httpx - INFO - HTTP Request: POST http://olvi-1:8000/embeddings \"HTTP/1.1 200 OK\"\n</pre> <pre>{'provider': &lt;Provider.TEXT_EMBEDDING_INFERENCE: 'tei'&gt;, 'model': 'intfloat/multilingual-e5-large-instruct', 'max_tokens': 512, 'dimensions': 1024, 'doc_prefix': '', 'query_prefix': 'Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery: '}\nDocument 1 vectors: [0.02874486893415451, 0.008454373106360435, -0.028976252302527428]...\nDocument 2 vectors: [0.026782996952533722, 0.00042712956201285124, 0.00021018773259129375]...\nCPU times: user 59.9 ms, sys: 0 ns, total: 59.9 ms\nWall time: 98.5 ms\n</pre> In\u00a0[10]: Copied! <pre>%%time\ncustom_embedding_config = EmbeddingConfig(\n    provider=\"openai\",\n    server_url=\"https://api.openai.com/v1\",\n    model=\"text-embedding-3-small\",\n    dimensions=1536,\n    max_tokens=1000,\n    metric_type=\"IP\",\n)\ncustom_embedder = get_embedder(custom_embedding_config)\nprint(custom_embedder.info)\n\ncustom_vector = custom_embedder.embed(text=[\"This is a test document.\", \"This is another sentence.\"], text_type=\"doc\")\nprint(f\"Custom embedder vectors: {custom_vector[0][:3]}...\")\nprint(f\"Custom embedder vectors: {custom_vector[1][:3]}...\")\n</pre> %%time custom_embedding_config = EmbeddingConfig(     provider=\"openai\",     server_url=\"https://api.openai.com/v1\",     model=\"text-embedding-3-small\",     dimensions=1536,     max_tokens=1000,     metric_type=\"IP\", ) custom_embedder = get_embedder(custom_embedding_config) print(custom_embedder.info)  custom_vector = custom_embedder.embed(text=[\"This is a test document.\", \"This is another sentence.\"], text_type=\"doc\") print(f\"Custom embedder vectors: {custom_vector[0][:3]}...\") print(f\"Custom embedder vectors: {custom_vector[1][:3]}...\") <pre>2025-07-23 19:40:35,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-07-23 19:40:35,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n</pre> <pre>{'provider': &lt;Provider.OPENAI: 'openai'&gt;, 'model': 'text-embedding-3-small', 'dimensions': 1536, 'doc_prefix': '', 'query_prefix': ''}\nCustom embedder vectors: [-0.0023375607561320066, 0.05312768369913101, 0.03345499932765961]...\nCustom embedder vectors: [0.03686746209859848, 0.00252012861892581, -0.024845464155077934]...\nCPU times: user 36.8 ms, sys: 429 \u03bcs, total: 37.3 ms\nWall time: 960 ms\n</pre>"},{"location":"examples/embedder/#embedder","title":"Embedder\u00b6","text":"<ul> <li><code>BEAR</code> supports embedding with both <code>OpenAI</code> and self-hosted Text Embedding Inference server.</li> <li>Each <code>bear.model.Resource</code> must have an <code>embedding</code> field, configured via EmbeddingConfig. This defines the embedding server, model, and Milvus index settings.</li> <li>The default embedder is set using <code>.env</code> variables with the prefix <code>DEFAULT_EMBEDDING_XXX</code>.</li> <li>For details, see embedding.py.</li> </ul>"},{"location":"examples/embedder/#default-embedder-usage","title":"Default embedder usage\u00b6","text":""},{"location":"examples/embedder/#custom-embedder","title":"Custom embedder\u00b6","text":""},{"location":"reference/api/","title":"API Reference","text":""},{"location":"reference/api/#bear.api","title":"<code>bear.api</code>","text":""},{"location":"reference/api/#bear.api.lifespan","title":"<code>lifespan(app)</code>  <code>async</code>","text":"<p>Lifespan event handler for FastAPI to manage startup and shutdown tasks.</p> Source code in <code>bear/api.py</code> <pre><code>@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Lifespan event handler for FastAPI to manage startup and shutdown tasks.\"\"\"\n    app_state[\"search_engine\"] = SearchEngine()\n    yield\n    app_state.clear()  # Clear the app state on shutdown\n</code></pre>"},{"location":"reference/api/#bear.api.read_root","title":"<code>read_root()</code>","text":"<p>Root endpoint to provide instructions for using the API.</p> Source code in <code>bear/api.py</code> <pre><code>@app.get(\"/\")\ndef read_root():\n    \"\"\"Root endpoint to provide instructions for using the API.\"\"\"\n    return {\"Instruction\": \"Try /search_resource?query=your_query_here&amp;top_k=3 or /search_author?query=your_query_here&amp;top_k=3\"}\n</code></pre>"},{"location":"reference/api/#bear.api.search_resource_route","title":"<code>search_resource_route(query=Query(..., title='The query string to search for.'), top_k=Query(3, title='The number of results to return.'), resource_name=Query('work', title='The resource type to search (default: work).'), min_distance=Query(None, title='Minimum distance threshold for results.'), since_year=Query(None, title='Filter results from this year onwards.'))</code>","text":"<p>Search for resources based on the provided query and parameters.</p> Source code in <code>bear/api.py</code> <pre><code>@app.get(\"/search_resource\", response_model=list[ResourceSearchResult])\ndef search_resource_route(\n    query: str = Query(..., title=\"The query string to search for.\"),\n    top_k: int = Query(3, title=\"The number of results to return.\"),\n    resource_name: str = Query(\"work\", title=\"The resource type to search (default: work).\"),\n    min_distance: float | None = Query(None, title=\"Minimum distance threshold for results.\"),\n    since_year: int | None = Query(None, title=\"Filter results from this year onwards.\"),\n):\n    \"\"\"Search for resources based on the provided query and parameters.\"\"\"\n    try:\n        results = app_state[\"search_engine\"].search_resource(\n            resource_name=resource_name, query=query, top_k=top_k, min_distance=min_distance, since_year=since_year\n        )\n\n        if not results:\n            raise HTTPException(status_code=404, detail=\"No results found.\")\n\n        # Convert results to response format\n        formatted_results = []\n        for result in results:\n            entity = result.get(\"entity\", {})\n            # Add abstract from inverted index if available\n            abstract = None\n            if \"abstract_inverted_index\" in entity and entity[\"abstract_inverted_index\"]:\n                abstract = Work._recover_abstract(entity[\"abstract_inverted_index\"])\n\n            formatted_results.append(\n                ResourceSearchResult(\n                    id=entity.get(\"id\", \"\"),\n                    doi=entity.get(\"doi\"),\n                    title=entity.get(\"title\"),\n                    display_name=entity.get(\"display_name\"),\n                    publication_year=entity.get(\"publication_year\"),\n                    publication_date=entity.get(\"publication_date\"),\n                    type=entity.get(\"type\"),\n                    cited_by_count=entity.get(\"cited_by_count\"),\n                    source_display_name=entity.get(\"source_display_name\"),\n                    topics=entity.get(\"topics\", []),\n                    abstract=abstract,\n                    distance=result.get(\"distance\", 0.0),\n                    author_ids=entity.get(\"author_ids\", []),\n                )\n            )\n\n        return formatted_results\n\n    except HTTPException:\n        # Re-raise HTTPExceptions (like 404) without modification\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n</code></pre>"},{"location":"reference/api/#bear.api.search_author_route","title":"<code>search_author_route(query=Query(..., title='The query string to search for authors.'), top_k=Query(3, title='The number of results to return.'), institutions=Query(None, title='Filter authors by institutions.'), min_distance=Query(None, title='Minimum distance threshold for results.'), since_year=Query(None, title='Filter results from this year onwards.'))</code>","text":"<p>Search for authors based on the provided query and parameters.</p> Source code in <code>bear/api.py</code> <pre><code>@app.get(\"/search_author\", response_model=list[AuthorSearchResult])\ndef search_author_route(\n    query: str = Query(..., title=\"The query string to search for authors.\"),\n    top_k: int = Query(3, title=\"The number of results to return.\"),\n    institutions: list[str] | None = Query(None, title=\"Filter authors by institutions.\"),\n    min_distance: float | None = Query(None, title=\"Minimum distance threshold for results.\"),\n    since_year: int | None = Query(None, title=\"Filter results from this year onwards.\"),\n):\n    \"\"\"Search for authors based on the provided query and parameters.\"\"\"\n    try:\n        results = app_state[\"search_engine\"].search_author(\n            query=query, top_k=top_k, institutions=institutions, min_distance=min_distance, since_year=since_year\n        )\n\n        if not results:\n            raise HTTPException(status_code=404, detail=\"No results found.\")\n\n        return [AuthorSearchResult(author_id=result[\"author_id\"], score=result[\"score\"]) for result in results]\n\n    except HTTPException:\n        # Re-raise HTTPExceptions (like 404) without modification\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Author search failed: {str(e)}\")\n</code></pre>"},{"location":"reference/api/#endpoints","title":"Endpoints","text":"<p>The BEAR API provides RESTful endpoints for searching academic resources and authors.</p>"},{"location":"reference/api/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000\n</code></pre>"},{"location":"reference/api/#authentication","title":"Authentication","text":"<p>Currently, no authentication is required for API access.</p>"},{"location":"reference/api/#response-format","title":"Response Format","text":"<p>All responses are in JSON format. Successful responses return the requested data, while errors return an error object with a message.</p>"},{"location":"reference/api/#error-handling","title":"Error Handling","text":"<p>The API uses standard HTTP status codes:</p> <ul> <li><code>200 OK</code> - Request successful</li> <li><code>404 Not Found</code> - No results found</li> <li><code>422 Unprocessable Entity</code> - Invalid request parameters</li> <li><code>500 Internal Server Error</code> - Server error</li> </ul>"},{"location":"reference/api/#models","title":"Models","text":""},{"location":"reference/api/#resourcesearchresult","title":"ResourceSearchResult","text":"<p>Response model for resource search results.</p>"},{"location":"reference/api/#authorsearchresult","title":"AuthorSearchResult","text":"<p>Response model for author search results.</p>"},{"location":"reference/config/","title":"Config Reference","text":""},{"location":"reference/config/#bear.config","title":"<code>bear.config</code>","text":""},{"location":"reference/config/#bear.config.EmbeddingConfig","title":"<code>EmbeddingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>bear/config.py</code> <pre><code>class EmbeddingConfig(BaseModel):\n    provider: str\n    server_url: str\n    model: str\n    dimensions: int\n    max_tokens: int\n    doc_prefix: str = \"\"\n    query_prefix: str = \"\"\n    api_key: SecretStr | None = None\n\n    # Index settings\n    index_type: str = \"HNSW\"\n    metric_type: str = \"IP\"\n    hnsw_m: int = 64\n    hnsw_ef_construction: int = 256\n\n    @property\n    def index_config(self) -&gt; dict:\n        \"\"\"Return the index configuration dict for Milvus. Note. Missing `field_name` should be injected from the model definition.\"\"\"\n        assert self.index_type == \"HNSW\", \"Only HNSW index type is supported in BEAR for now. Send a PR if you need other index types.\"\n\n        return {\n            \"index_type\": self.index_type,\n            \"metric_type\": self.metric_type,\n            \"params\": {\n                \"M\": self.hnsw_m,\n                \"efConstruction\": self.hnsw_ef_construction,\n            },\n        }\n</code></pre>"},{"location":"reference/config/#bear.config.EmbeddingConfig.index_config","title":"<code>index_config</code>  <code>property</code>","text":"<p>Return the index configuration dict for Milvus. Note. Missing <code>field_name</code> should be injected from the model definition.</p>"},{"location":"reference/config/#bear.config.Config","title":"<code>Config</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>System configuration. Settings are defined in <code>.env</code>. Refer to <code>example.env</code> for details.</p> Source code in <code>bear/config.py</code> <pre><code>class Config(BaseSettings):\n    \"\"\"System configuration. Settings are defined in `.env`. Refer to `example.env` for details.\"\"\"\n\n    model_config = SettingsConfigDict(env_file=\".env\")\n\n    # (Optional) OpenAlex data dump database\n    POSTGRES_USER: SecretStr | None = None\n    POSTGRES_PASSWORD: SecretStr | None = None\n    POSTGRES_URL: SecretStr | None = None\n\n    # Milvus\n    MINIO_ACCESS_KEY: SecretStr | None = None\n    MINIO_SECRET_KEY: SecretStr | None = None\n    MILVUS_TOKEN: SecretStr | None = None\n    MILVUS_HOST: str = \"localhost\"\n    MILVUS_PORT: int = 19530\n    MILVUS_DB_NAME: str = \"dev\"\n\n    # External APIs\n    OPENALEX_MAILTO_EMAIL: str = \"\"\n    OPENAI_API_KEY: SecretStr | None = None\n    TEI_API_KEY: SecretStr | None = None\n\n    # Embeddings\n    DEFAULT_EMBEDDING_PROVIDER: str = \"openai\"\n    DEFAULT_EMBEDDING_SERVER_URL: str = \"https://api.openai.com/v1\"\n    DEFAULT_EMBEDDING_MODEL: str = \"text-embedding-3-large\"\n    DEFAULT_EMBEDDING_DIMS: int = 3072\n    DEFAULT_EMBEDDING_MAX_TOKENS: int = 512\n    DEFAULT_EMBEDDING_DOC_PREFIX: str = \"\"\n    DEFAULT_EMBEDDING_QUERY_PREFIX: str = \"\"\n\n    # Embeddings Index\n    DEFAULT_INDEX_TYPE: str = \"HNSW\"\n    DEFAULT_METRIC_TYPE: str = \"IP\"\n    DEFAULT_HNSW_M: int = 32\n    DEFAULT_HNSW_EF_CONSTRUCTION: int = 512\n\n    # Logging\n    LOG_LEVEL: str = \"DEBUG\"\n\n    @property\n    def DEFAULT_EMBEDDING_API_KEY(self) -&gt; SecretStr | None:\n        \"\"\"Return the default embedding API key based on the provider.\"\"\"\n        if self.DEFAULT_EMBEDDING_PROVIDER == \"openai\":\n            logger.debug(f\"Using OpenAI API key for default key: {self.OPENAI_API_KEY}\")\n            return self.OPENAI_API_KEY\n        elif self.DEFAULT_EMBEDDING_PROVIDER == \"tei\":\n            logger.debug(f\"Using Text Embedding Inference API key for default key: {self.TEI_API_KEY}\")\n            return self.TEI_API_KEY\n        return None\n\n    @property\n    def default_embedding_config(self) -&gt; EmbeddingConfig:\n        \"\"\"Return the default embedding configuration.\"\"\"\n        return EmbeddingConfig(\n            provider=self.DEFAULT_EMBEDDING_PROVIDER,\n            server_url=self.DEFAULT_EMBEDDING_SERVER_URL,\n            model=self.DEFAULT_EMBEDDING_MODEL,\n            dimensions=self.DEFAULT_EMBEDDING_DIMS,\n            max_tokens=self.DEFAULT_EMBEDDING_MAX_TOKENS,\n            doc_prefix=self.DEFAULT_EMBEDDING_DOC_PREFIX,\n            query_prefix=self.DEFAULT_EMBEDDING_QUERY_PREFIX,\n            api_key=self.DEFAULT_EMBEDDING_API_KEY,\n            index_type=self.DEFAULT_INDEX_TYPE,\n            metric_type=self.DEFAULT_METRIC_TYPE,\n            hnsw_m=self.DEFAULT_HNSW_M,\n            hnsw_ef_construction=self.DEFAULT_HNSW_EF_CONSTRUCTION,\n        )\n</code></pre>"},{"location":"reference/config/#bear.config.Config.DEFAULT_EMBEDDING_API_KEY","title":"<code>DEFAULT_EMBEDDING_API_KEY</code>  <code>property</code>","text":"<p>Return the default embedding API key based on the provider.</p>"},{"location":"reference/config/#bear.config.Config.default_embedding_config","title":"<code>default_embedding_config</code>  <code>property</code>","text":"<p>Return the default embedding configuration.</p>"},{"location":"reference/config/#configuration-options","title":"Configuration Options","text":"<p>BEAR uses environment variables for configuration. Create a <code>.env</code> file in the project root with your settings.</p>"},{"location":"reference/config/#database-configuration","title":"Database Configuration","text":"<p>Configuration for PostgreSQL and Milvus vector database connections.</p>"},{"location":"reference/config/#openai-configuration","title":"OpenAI Configuration","text":"<p>Settings for OpenAI API integration for embeddings.</p>"},{"location":"reference/config/#crawler-configuration","title":"Crawler Configuration","text":"<p>Options for controlling data crawling from OpenAlex.</p>"},{"location":"reference/config/#example-configuration","title":"Example Configuration","text":"<p>See <code>example.env</code> for a complete configuration template.</p>"},{"location":"reference/crawler/","title":"Crawler Reference","text":""},{"location":"reference/crawler/#bear.crawler","title":"<code>bear.crawler</code>","text":""},{"location":"reference/crawler/#bear.crawler.strip_oa_prefix","title":"<code>strip_oa_prefix(id)</code>","text":"<p>Remove the OpenAlex ID prefix.</p> Source code in <code>bear/crawler.py</code> <pre><code>def strip_oa_prefix(id: str) -&gt; str:\n    \"\"\"Remove the OpenAlex ID prefix.\"\"\"\n    return id.lstrip(\"https://openalex.org/\")\n</code></pre>"},{"location":"reference/crawler/#bear.crawler.get_openalex_id","title":"<code>get_openalex_id(entity_type, name)</code>","text":"<p>Get an OpenAlex ID for a given entity type and search name with retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of entity to search for. Must be one of \"authors\" or \"institutions\".</p> required <code>name</code> <code>str</code> <p>The name to search for.</p> required Example <p>get_openalex_id(\"authors\", \"Jason Chor Ming Lo\") get_openalex_id(\"institutions\", \"University of Wisconsin-Madison\")</p> Source code in <code>bear/crawler.py</code> <pre><code>@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(min=1, max=30),\n    retry=retry_if_exception_type((httpx.HTTPError, httpx.TimeoutException)),\n    reraise=True,\n)\ndef get_openalex_id(entity_type: str, name: str) -&gt; str:\n    \"\"\"\n    Get an OpenAlex ID for a given entity type and search name with retry logic.\n\n    Args:\n        entity_type: The type of entity to search for. Must be one of \"authors\" or \"institutions\".\n        name: The name to search for.\n\n    Example:\n        get_openalex_id(\"authors\", \"Jason Chor Ming Lo\")\n        get_openalex_id(\"institutions\", \"University of Wisconsin-Madison\")\n    \"\"\"\n    if entity_type not in (\"authors\", \"institutions\"):\n        raise ValueError(\"entity_type must be 'authors' or 'institutions'\")\n\n    url = f\"https://api.openalex.org/{entity_type}?search={name}\"\n    if config.OPENALEX_MAILTO_EMAIL:\n        url += f\"&amp;mailto={config.OPENALEX_MAILTO_EMAIL}\"\n\n    try:\n        response = httpx.get(url)\n        response.raise_for_status()\n        results = response.json().get(\"results\")\n\n        if not results:\n            raise ValueError(f\"No {entity_type.rstrip('s')} found for query: {name}\")\n\n        logger.info(f\"Found: {results[0]['display_name']} ({results[0]['id']})\")\n        return strip_oa_prefix(results[0][\"id\"])\n    except (httpx.HTTPError, httpx.TimeoutException) as e:\n        logger.warning(f\"Error retrieving {entity_type} ID: {str(e)}. Retrying...\")\n        raise\n</code></pre>"},{"location":"reference/crawler/#bear.crawler.query_openalex","title":"<code>query_openalex(endpoint, query, limit=0, save_folder=None)</code>","text":"<p>Get all results from the OpenAlex API for a given endpoint and query.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>The API endpoint to query (e.g., \"works\", \"authors\").</p> required <code>query</code> <code>str</code> <p>The filter query for the API.</p> required <code>limit</code> <code>int</code> <p>The maximum number of pages (round trips) to retrieve.    If 0 (default), all pages are retrieved.</p> <code>0</code> <code>save_folder</code> <code>Path | None</code> <p>Optional folder to save results as a Parquet file.</p> <code>None</code> Example <pre><code># Get works authored by a specific institution\nquery_openalex(\"works\", \"authorships.institutions.lineage:I135310074,type:types/article\", limit=5)\n\n# Get authors affiliated with a specific institution\nquery_openalex(\"authors\", \"last_known_institutions.id:https://openalex.org/I135310074\", limit=3)\n</code></pre> Source code in <code>bear/crawler.py</code> <pre><code>def query_openalex(endpoint: str, query: str, limit: int = 0, save_folder: Path | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"Get all results from the OpenAlex API for a given endpoint and query.\n\n    Args:\n        endpoint: The API endpoint to query (e.g., \"works\", \"authors\").\n        query: The filter query for the API.\n        limit: The maximum number of pages (round trips) to retrieve.\n               If 0 (default), all pages are retrieved.\n        save_folder: Optional folder to save results as a Parquet file.\n\n    Example:\n        ```python\n        # Get works authored by a specific institution\n        query_openalex(\"works\", \"authorships.institutions.lineage:I135310074,type:types/article\", limit=5)\n\n        # Get authors affiliated with a specific institution\n        query_openalex(\"authors\", \"last_known_institutions.id:https://openalex.org/I135310074\", limit=3)\n        ```\n    \"\"\"\n\n    if save_folder is not None:\n        save_folder.mkdir(parents=True, exist_ok=True)\n\n    cursor = \"*\"\n    all_results = []\n    round_trips = 0\n    save_counter = 0\n    while True:\n        if limit &gt; 0 and round_trips &gt;= limit:\n            logger.warning(f\"Reached API call limit of {limit} for endpoint '{endpoint}' with query: {query}. Results will be incomplete.\")\n            break\n\n        cursor, results = _get_page_results(endpoint, query, cursor)\n        round_trips += 1\n\n        if not results:\n            break\n        all_results.extend(results)\n\n        # Save results to Parquet file if specified\n        if save_folder and len(all_results) &gt;= 1000:  # Save every 1000 records\n            chunk_file = save_folder / f\"chunk_{save_counter}.parquet\"\n            logger.info(f\"Saving {len(all_results)} results to {chunk_file}\")\n            _dump(all_results, chunk_file)\n            save_counter += 1\n            all_results = []  # Reset for next chunk\n\n        logger.info(f\"Retrieved {len(all_results)} results so far for query: {query}\")\n\n    if save_folder and all_results:\n        chunk_file = save_folder / f\"chunk_{save_counter}.parquet\"\n        logger.info(f\"Saving final {len(all_results)} results to {chunk_file}\")\n        _dump(all_results, chunk_file)\n    return all_results\n</code></pre>"},{"location":"reference/crawler/#bear.crawler.crawl","title":"<code>crawl(institution, save_path=Path('tmp/openalex_data'), author_api_call_limit=0, authors_limit=0, per_author_work_api_call_limit=0, skip_pulling_authors=False, skip_existing_works=True)</code>","text":"<p>Crawl the OpenAlex API and dump the results to local storage.</p> Source code in <code>bear/crawler.py</code> <pre><code>def crawl(\n    institution: str,\n    save_path: Path = Path(\"tmp/openalex_data\"),\n    author_api_call_limit: int = 0,\n    authors_limit: int = 0,\n    per_author_work_api_call_limit: int = 0,\n    skip_pulling_authors: bool = False,\n    skip_existing_works: bool = True,\n) -&gt; None:\n    \"\"\"Crawl the OpenAlex API and dump the results to local storage.\"\"\"\n\n    save_path.mkdir(parents=True, exist_ok=True)\n\n    # Get existing authors if skip_existing is True\n    if skip_existing_works and (save_path / \"authors\").exists():\n        existing_authors = [p.name for p in Path(\"tmp/openalex_data/works/\").glob(\"*/\")]\n\n    if not skip_pulling_authors:\n        # Get all authors affiliated with the institution\n        institution_id = get_openalex_id(\"institutions\", institution)\n\n        logger.info(f\"Fetching authors for institution ID: {institution_id}\")\n        query_authors = f\"last_known_institutions.id:{institution_id}\"\n        query_openalex(endpoint=\"authors\", query=query_authors, limit=author_api_call_limit, save_folder=save_path / \"authors\")\n        authors = pd.read_parquet(save_path / \"authors\").to_dict(orient=\"records\")\n    else:\n        # If skipping pulling authors, use existing authors from previous runs\n        if (save_path / \"authors\").exists():\n            authors = pd.read_parquet(save_path / \"authors\").to_dict(orient=\"records\")\n        else:\n            logger.warning(\"Skipping pulling authors, but no existing authors found.\")\n            authors = []\n\n    # Get all works authored by the institution's authors\n    if authors_limit &gt; 0:\n        authors = authors[:authors_limit]\n\n    if skip_existing_works:\n        authors = [a for a in authors if strip_oa_prefix(a[\"id\"]) not in existing_authors]\n\n    for author in tqdm(authors):\n        try:\n            author_id = strip_oa_prefix(author[\"id\"])\n\n            query_works = f\"authorships.author.id:{author_id}\"\n            query_openalex(endpoint=\"works\", query=query_works, limit=per_author_work_api_call_limit, save_folder=save_path / \"works\" / author_id)\n        except Exception as e:\n            logger.error(f\"Error processing author {author_id}: {str(e)}\")\n            continue\n</code></pre>"},{"location":"reference/crawler/#openalex-data-crawler","title":"OpenAlex Data Crawler","text":"<p>The crawler module handles data collection from the OpenAlex API.</p>"},{"location":"reference/crawler/#features","title":"Features","text":"<ul> <li>Institution-specific data crawling</li> <li>Rate limiting and retry logic</li> <li>Parallel processing support</li> <li>Data validation and cleaning</li> </ul>"},{"location":"reference/crawler/#usage","title":"Usage","text":"<pre><code>uv run bear/crawler.py &lt;institution-id&gt;\n</code></pre>"},{"location":"reference/crawler/#data-output","title":"Data Output","text":"<p>Crawled data is saved in parquet format in the <code>tmp/openalex_data/</code> directory.</p>"},{"location":"reference/db/","title":"Database Reference","text":""},{"location":"reference/db/#bear.db","title":"<code>bear.db</code>","text":""},{"location":"reference/db/#bear.db.get_milvus_client","title":"<code>get_milvus_client(db_name=config.MILVUS_DB_NAME)</code>","text":"<p>Get or create Milvus client.</p> Source code in <code>bear/db.py</code> <pre><code>def get_milvus_client(db_name: str = config.MILVUS_DB_NAME) -&gt; MilvusClient:\n    \"\"\"Get or create Milvus client.\"\"\"\n    uri = f\"http://{config.MILVUS_HOST}:{config.MILVUS_PORT}\"\n    token = config.MILVUS_TOKEN if config.MILVUS_TOKEN else \"\"\n    client = MilvusClient(uri=uri, token=str(token))\n    client.use_database(db_name)\n    return client\n</code></pre>"},{"location":"reference/db/#bear.db.create_milvus_collection","title":"<code>create_milvus_collection(client, model, auto_id=False, enable_dynamic_field=True)</code>","text":"<p>Create a Milvus collection for the given model.</p> Source code in <code>bear/db.py</code> <pre><code>def create_milvus_collection(client: MilvusClient, model: type[Resource], auto_id: bool = False, enable_dynamic_field: bool = True) -&gt; None:\n    \"\"\"Create a Milvus collection for the given model.\"\"\"\n\n    if model not in ALL_RESOURCES:\n        raise ValueError(f\"Model {model} is not registered in bear.model.ALL_MODELS.\")\n\n    collection_name = model.__name__.lower()  # Not instantiated, just use the class name\n\n    if client.has_collection(collection_name):\n        logger.info(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n        return\n\n    # Initialize collection with schema and index parameters\n    schema = client.create_schema(auto_id=auto_id, enable_dynamic_field=enable_dynamic_field)\n    index_params = client.prepare_index_params()\n    for field_name, field_info in model.model_fields.items():\n        assert len(field_info.metadata) == 1, f\"Field {field_name} should have exactly one metadata entry.\"\n        milvus_metadata = field_info.metadata[0].json_schema\n\n        if \"index_configs\" in milvus_metadata:\n            index_config = milvus_metadata.pop(\"index_configs\")\n            logger.info(f\"Adding index for field {field_name} with config {index_config}\")\n            index_params.add_index(field_name=field_name, **index_config)\n\n        logger.info(f\"Adding field {field_name} with schema {milvus_metadata}\")\n        schema.add_field(field_name=field_name, **milvus_metadata)\n\n    logger.info(f\"Creating collection '{collection_name}' with schema and index parameters.\")\n    client.create_collection(collection_name=collection_name, schema=schema, index_params=index_params)\n</code></pre>"},{"location":"reference/db/#bear.db.init","title":"<code>init(db_name=config.MILVUS_DB_NAME, wipe=False)</code>","text":"<p>Initialize Milvus collection.</p> Source code in <code>bear/db.py</code> <pre><code>def init(db_name: str = config.MILVUS_DB_NAME, wipe: bool = False) -&gt; None:\n    \"\"\"Initialize Milvus collection.\"\"\"\n\n    client = get_milvus_client(db_name=db_name)\n\n    if wipe and db_name in client.list_databases():\n        logger.info(f\"Wiping database: {db_name}\")\n        [client.drop_collection(x) for x in client.list_collections()]\n        client.drop_database(db_name=db_name)\n\n    if db_name not in client.list_databases():\n        logger.info(f\"Creating database: {db_name}\")\n        client.create_database(db_name=db_name)\n\n    client.use_database(db_name)\n\n    for model in ALL_RESOURCES:\n        create_milvus_collection(client=client, model=model)\n</code></pre>"},{"location":"reference/db/#bear.db.push","title":"<code>push(resources, db_name=config.MILVUS_DB_NAME)</code>","text":"<p>Upsert resources into Milvus. This method is slower but ensures no duplicate IDs.</p> Source code in <code>bear/db.py</code> <pre><code>def push(resources: list[ResourceType], db_name: str = config.MILVUS_DB_NAME) -&gt; None:\n    \"\"\"Upsert resources into Milvus. This method is slower but ensures no duplicate IDs.\"\"\"\n    client = get_milvus_client()\n    client.use_database(db_name)\n    collection_name = resources[0]._name\n\n    if not client.has_collection(collection_name):\n        raise ValueError(f\"Collection '{collection_name}' does not exist. Please create it first.\")\n\n    data = [resource.to_milvus() for resource in resources]\n    client.insert(collection_name=collection_name, data=data)\n    logger.info(f\"Inserted {len(resources)} resources into collection '{collection_name}'.\")\n</code></pre>"},{"location":"reference/db/#database-management","title":"Database Management","text":"<p>The database module handles connections and operations with both PostgreSQL and Milvus vector database.</p>"},{"location":"reference/db/#features","title":"Features","text":"<ul> <li>PostgreSQL connection management</li> <li>Milvus vector database operations</li> <li>Connection pooling</li> <li>Error handling and retries</li> </ul>"},{"location":"reference/db/#database-schema","title":"Database Schema","text":"<p>Information about the database schema and table structures used by BEAR.</p>"},{"location":"reference/docs/","title":"Documentation","text":""},{"location":"reference/docs/#overview","title":"Overview","text":"<p>This project uses MkDocs for documentation with the following stack:</p> <ul> <li>Engine: MkDocs</li> <li>Docstring: mkdocstrings (Python)</li> <li>Jupyter: mkdocs-jupyter</li> <li>Theme: mkdocs-shadcn</li> <li>Minify: mkdocs-minify-plugin</li> </ul>"},{"location":"reference/docs/#quick-commands","title":"Quick Commands","text":"<pre><code># Install documentation dependencies\nuv sync --group docs\n\n# Serve documentation locally\nuv run mkdocs serve\n\n# Build documentation\nuv run mkdocs build\n\n# Deploy to GitHub Pages\nuv run mkdocs gh-deploy\n</code></pre>"},{"location":"reference/docs/#vs-code-tasks","title":"VS Code Tasks","text":"<p>The following tasks are available in VS Code:</p> <ul> <li><code>docs-serve</code> - Start development server</li> <li><code>docs-build</code> - Build static documentation</li> <li><code>docs-deploy</code> - Deploy to GitHub Pages</li> </ul>"},{"location":"reference/docs/#file-structure","title":"File Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                 # Home page\n\u251c\u2500\u2500 getting-started.md       # Installation and setup\n\u251c\u2500\u2500 usage.md                 # Usage guide\n\u251c\u2500\u2500 reference/               # API reference docs\n\u2502   \u251c\u2500\u2500 api.md\n\u2502   \u251c\u2500\u2500 config.md\n\u2502   \u251c\u2500\u2500 crawler.md\n\u2502   \u251c\u2500\u2500 db.md\n\u2502   \u251c\u2500\u2500 embedding.md\n\u2502   \u251c\u2500\u2500 ingest.md\n\u2502   \u251c\u2500\u2500 model.md\n\u2502   \u2514\u2500\u2500 search.md\n\u2514\u2500\u2500 notebooks/\n    \u251c\u2500\u2500 api_usage.ipynb\n    \u251c\u2500\u2500 benchmark_inference_servers.ipynb\n    \u2514\u2500\u2500 embedder.ipynb\n</code></pre>"},{"location":"reference/docs/#configuration","title":"Configuration","text":"<p>Documentation configuration is in <code>mkdocs.yml</code>. Key features:</p> <ul> <li>Shadcn theme with modern design</li> <li>Code highlighting and copy buttons</li> <li>Search functionality</li> <li>Automatic API documentation generation</li> <li>Jupyter notebook integration</li> <li>HTML minification for production</li> </ul>"},{"location":"reference/docs/#deployment","title":"Deployment","text":"<p>The documentation can be deployed to GitHub Pages using:</p> <pre><code>uv run mkdocs gh-deploy\n</code></pre> <p>This will build the documentation and push it to the <code>gh-pages</code> branch.</p>"},{"location":"reference/embedding/","title":"Embedding Reference","text":""},{"location":"reference/embedding/#bear.embedding","title":"<code>bear.embedding</code>","text":""},{"location":"reference/embedding/#bear.embedding.TextType","title":"<code>TextType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Type of text to embed.</p> Source code in <code>bear/embedding.py</code> <pre><code>class TextType(StrEnum):\n    \"\"\"Type of text to embed.\"\"\"\n\n    DOC = \"doc\"\n    QUERY = \"query\"\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.Provider","title":"<code>Provider</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Embedding providers.</p> Source code in <code>bear/embedding.py</code> <pre><code>class Provider(StrEnum):\n    \"\"\"Embedding providers.\"\"\"\n\n    OPENAI = \"openai\"\n    TEXT_EMBEDDING_INFERENCE = \"tei\"\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.Embedder","title":"<code>Embedder</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for embedding text into vector representations.</p> Example <pre><code>from bear.config import config\nfrom bear.embedding import get_embedder\n\nembedder = get_embedder(config.embedding_config)\n\n# Show info\nprint(embedder.info)\n\n# Embed a document\nembedder.embed(\"hi\", text_type=\"doc\")\n\n# Embed a query\nembedder.embed(\"What is good at cooking?\", text_type=\"query\")\n</code></pre> Source code in <code>bear/embedding.py</code> <pre><code>class Embedder(Protocol):\n    \"\"\"Protocol for embedding text into vector representations.\n\n    Example:\n        ```python\n        from bear.config import config\n        from bear.embedding import get_embedder\n\n        embedder = get_embedder(config.embedding_config)\n\n        # Show info\n        print(embedder.info)\n\n        # Embed a document\n        embedder.embed(\"hi\", text_type=\"doc\")\n\n        # Embed a query\n        embedder.embed(\"What is good at cooking?\", text_type=\"query\")\n        ```\n    \"\"\"\n\n    def embed(self, text: str | list[str], text_type: TextType | str) -&gt; list[list[float]]: ...\n\n    @property\n    def info(self) -&gt; dict[str, Any]: ...\n\n    @classmethod\n    def from_config(cls, embedding_config: EmbeddingConfig) -&gt; \"Embedder\": ...\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.OpenAIEmbedder","title":"<code>OpenAIEmbedder</code>","text":"<p>Embedder using OpenAI's API.</p> Source code in <code>bear/embedding.py</code> <pre><code>class OpenAIEmbedder:\n    \"\"\"Embedder using OpenAI's API.\"\"\"\n\n    def __init__(self, model: str, max_tokens: int, doc_prefix: str = \"\", query_prefix: str = \"\", api_key: str | None = None, **kwargs) -&gt; None:\n        self.client = OpenAI(api_key=api_key)\n        self.model = model\n        self.max_tokens = max_tokens\n        self.doc_prefix = doc_prefix\n        self.query_prefix = query_prefix\n\n    @classmethod\n    def from_config(cls, embedding_config: EmbeddingConfig) -&gt; \"OpenAIEmbedder\":\n        \"\"\"Create an OpenAIEmbedder instance from configuration.\"\"\"\n        return cls(\n            model=embedding_config.model,\n            max_tokens=embedding_config.max_tokens,\n            doc_prefix=embedding_config.doc_prefix,\n            query_prefix=embedding_config.query_prefix,\n            api_key=str(embedding_config.api_key) if embedding_config.api_key else None,\n        )\n\n    @property\n    def info(self) -&gt; dict[str, Any]:\n        \"\"\"Return information about the OpenAI embedder.\"\"\"\n        return {\n            \"provider\": Provider.OPENAI,\n            \"model\": self.model,\n            \"dimensions\": self.get_dimensions(),\n            \"doc_prefix\": self.doc_prefix,\n            \"query_prefix\": self.query_prefix,\n        }\n\n    @cache\n    def get_dimensions(self) -&gt; int:\n        \"\"\"Get the dimensions of the embedding model.\"\"\"\n        response = self.client.embeddings.create(model=self.model, input=[\"test\"])\n        return len(response.data[0].embedding)\n\n    def embed(self, text: str | list[str], text_type: TextType | str) -&gt; list[list[float]]:\n        \"\"\"Use OpenAI to embed text into a vector representation.\"\"\"\n\n        if isinstance(text_type, str):\n            text_type = TextType(text_type)\n\n        assert text_type in (TextType.DOC, TextType.QUERY), \"text_type must be either 'doc' or 'query'\"\n        if text_type == TextType.DOC and self.doc_prefix:\n            text = append_prefix(text, self.doc_prefix)\n        elif text_type == TextType.QUERY and self.query_prefix:\n            text = append_prefix(text, self.query_prefix)\n\n        response = self.client.embeddings.create(model=self.model, input=text)\n        return [v.embedding for v in response.data]\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.OpenAIEmbedder.info","title":"<code>info</code>  <code>property</code>","text":"<p>Return information about the OpenAI embedder.</p>"},{"location":"reference/embedding/#bear.embedding.OpenAIEmbedder.from_config","title":"<code>from_config(embedding_config)</code>  <code>classmethod</code>","text":"<p>Create an OpenAIEmbedder instance from configuration.</p> Source code in <code>bear/embedding.py</code> <pre><code>@classmethod\ndef from_config(cls, embedding_config: EmbeddingConfig) -&gt; \"OpenAIEmbedder\":\n    \"\"\"Create an OpenAIEmbedder instance from configuration.\"\"\"\n    return cls(\n        model=embedding_config.model,\n        max_tokens=embedding_config.max_tokens,\n        doc_prefix=embedding_config.doc_prefix,\n        query_prefix=embedding_config.query_prefix,\n        api_key=str(embedding_config.api_key) if embedding_config.api_key else None,\n    )\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.OpenAIEmbedder.get_dimensions","title":"<code>get_dimensions()</code>  <code>cached</code>","text":"<p>Get the dimensions of the embedding model.</p> Source code in <code>bear/embedding.py</code> <pre><code>@cache\ndef get_dimensions(self) -&gt; int:\n    \"\"\"Get the dimensions of the embedding model.\"\"\"\n    response = self.client.embeddings.create(model=self.model, input=[\"test\"])\n    return len(response.data[0].embedding)\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.OpenAIEmbedder.embed","title":"<code>embed(text, text_type)</code>","text":"<p>Use OpenAI to embed text into a vector representation.</p> Source code in <code>bear/embedding.py</code> <pre><code>def embed(self, text: str | list[str], text_type: TextType | str) -&gt; list[list[float]]:\n    \"\"\"Use OpenAI to embed text into a vector representation.\"\"\"\n\n    if isinstance(text_type, str):\n        text_type = TextType(text_type)\n\n    assert text_type in (TextType.DOC, TextType.QUERY), \"text_type must be either 'doc' or 'query'\"\n    if text_type == TextType.DOC and self.doc_prefix:\n        text = append_prefix(text, self.doc_prefix)\n    elif text_type == TextType.QUERY and self.query_prefix:\n        text = append_prefix(text, self.query_prefix)\n\n    response = self.client.embeddings.create(model=self.model, input=text)\n    return [v.embedding for v in response.data]\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.TEIEmbedder","title":"<code>TEIEmbedder</code>","text":"<p>Embedder using Text Embedding Inference API (via OpenAI python client).</p> Source code in <code>bear/embedding.py</code> <pre><code>class TEIEmbedder:\n    \"\"\"Embedder using Text Embedding Inference API (via OpenAI python client).\"\"\"\n\n    def __init__(self, model: str, max_tokens: int, base_url: str, api_key: str = \"\", doc_prefix: str = \"\", query_prefix: str = \"\", **kwargs) -&gt; None:\n        self.model = model\n        self.max_tokens = max_tokens\n        self.base_url = base_url\n        self.client = OpenAI(base_url=base_url, api_key=api_key)\n        self.doc_prefix = doc_prefix\n        self.query_prefix = query_prefix\n        self._verify_server_match_model()\n\n    @classmethod\n    def from_config(cls, embedding_config: EmbeddingConfig) -&gt; \"TEIEmbedder\":\n        \"\"\"Create a TEIEmbedder instance from configuration.\"\"\"\n        return cls(\n            model=embedding_config.model,\n            max_tokens=embedding_config.max_tokens,\n            base_url=embedding_config.server_url,\n            api_key=str(embedding_config.api_key) if embedding_config.api_key else \"\",\n            doc_prefix=embedding_config.doc_prefix,\n            query_prefix=embedding_config.query_prefix,\n        )\n\n    @property\n    def info(self) -&gt; dict[str, Any]:\n        \"\"\"Return information about the TEI embedder.\"\"\"\n        return {\n            \"provider\": Provider.TEXT_EMBEDDING_INFERENCE,\n            \"model\": self.model,\n            \"max_tokens\": self.max_tokens,\n            \"dimensions\": self.get_dimensions(),\n            \"doc_prefix\": self.doc_prefix,\n            \"query_prefix\": self.query_prefix,\n        }\n\n    @cache\n    def _verify_server_match_model(self) -&gt; None:\n        \"\"\"Verify that the base URL matches the system settings.\"\"\"\n\n        with httpx.Client(base_url=self.base_url) as client:\n            response = client.get(\"/info\")\n            response.raise_for_status()\n            server_info = response.json()\n\n        if server_info.get(\"model_id\") != self.model:\n            raise ValueError(f\"Model ID {self.model} does not match server's model ID {server_info.get('model_id')}.\")\n\n        if server_info.get(\"max_input_length\") &lt; config.DEFAULT_EMBEDDING_MAX_TOKENS:\n            raise ValueError(\n                f\"Server's max input length {server_info.get('max_input_length')} is less than configured max tokens {config.DEFAULT_EMBEDDING_MAX_TOKENS}.\"\n            )\n\n    @cache\n    def get_dimensions(self) -&gt; int:\n        \"\"\"Get the dimensions of the embedding model.\"\"\"\n        response = self.client.embeddings.create(model=self.model, input=[\"test\"])\n        return len(response.data[0].embedding)\n\n    def embed(self, text: str | list[str], text_type: TextType | str) -&gt; list[list[float]]:\n        \"\"\"Use Text Embedding Inference to embed text into a vector representation.\"\"\"\n\n        if isinstance(text_type, str):\n            text_type = TextType(text_type)\n\n        if text_type == TextType.DOC and self.doc_prefix:\n            text = append_prefix(text, self.doc_prefix)\n        elif text_type == TextType.QUERY and self.query_prefix:\n            text = append_prefix(text, self.query_prefix)\n\n        response = self.client.embeddings.create(model=self.model, input=text)\n        return [v.embedding for v in response.data]\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.TEIEmbedder.info","title":"<code>info</code>  <code>property</code>","text":"<p>Return information about the TEI embedder.</p>"},{"location":"reference/embedding/#bear.embedding.TEIEmbedder.from_config","title":"<code>from_config(embedding_config)</code>  <code>classmethod</code>","text":"<p>Create a TEIEmbedder instance from configuration.</p> Source code in <code>bear/embedding.py</code> <pre><code>@classmethod\ndef from_config(cls, embedding_config: EmbeddingConfig) -&gt; \"TEIEmbedder\":\n    \"\"\"Create a TEIEmbedder instance from configuration.\"\"\"\n    return cls(\n        model=embedding_config.model,\n        max_tokens=embedding_config.max_tokens,\n        base_url=embedding_config.server_url,\n        api_key=str(embedding_config.api_key) if embedding_config.api_key else \"\",\n        doc_prefix=embedding_config.doc_prefix,\n        query_prefix=embedding_config.query_prefix,\n    )\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.TEIEmbedder.get_dimensions","title":"<code>get_dimensions()</code>  <code>cached</code>","text":"<p>Get the dimensions of the embedding model.</p> Source code in <code>bear/embedding.py</code> <pre><code>@cache\ndef get_dimensions(self) -&gt; int:\n    \"\"\"Get the dimensions of the embedding model.\"\"\"\n    response = self.client.embeddings.create(model=self.model, input=[\"test\"])\n    return len(response.data[0].embedding)\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.TEIEmbedder.embed","title":"<code>embed(text, text_type)</code>","text":"<p>Use Text Embedding Inference to embed text into a vector representation.</p> Source code in <code>bear/embedding.py</code> <pre><code>def embed(self, text: str | list[str], text_type: TextType | str) -&gt; list[list[float]]:\n    \"\"\"Use Text Embedding Inference to embed text into a vector representation.\"\"\"\n\n    if isinstance(text_type, str):\n        text_type = TextType(text_type)\n\n    if text_type == TextType.DOC and self.doc_prefix:\n        text = append_prefix(text, self.doc_prefix)\n    elif text_type == TextType.QUERY and self.query_prefix:\n        text = append_prefix(text, self.query_prefix)\n\n    response = self.client.embeddings.create(model=self.model, input=text)\n    return [v.embedding for v in response.data]\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.append_prefix","title":"<code>append_prefix(text, prefix)</code>","text":"<p>Append a prefix to the text or each item in the list.</p> Source code in <code>bear/embedding.py</code> <pre><code>def append_prefix(text: str | list[str], prefix: str) -&gt; list[str]:\n    \"\"\"Append a prefix to the text or each item in the list.\"\"\"\n    if isinstance(text, str):\n        return [f\"{prefix} {text}\"]\n    return [f\"{prefix} {t}\" for t in text]\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.get_embedder","title":"<code>get_embedder(embedding_config=config.default_embedding_config)</code>","text":"<p>Get the embedder instance based on configuration.</p> Source code in <code>bear/embedding.py</code> <pre><code>def get_embedder(embedding_config: EmbeddingConfig = config.default_embedding_config) -&gt; Embedder:\n    \"\"\"Get the embedder instance based on configuration.\"\"\"\n    if embedding_config.provider == \"openai\":\n        return OpenAIEmbedder.from_config(embedding_config)\n    elif embedding_config.provider == \"tei\":\n        return TEIEmbedder.from_config(embedding_config)\n    raise ValueError(f\"Unknown embedding provider: {embedding_config.provider}\")\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.embed_query","title":"<code>embed_query(query, embedding_config=config.default_embedding_config)</code>","text":"<p>Embed a query string into a vector representation.</p> Source code in <code>bear/embedding.py</code> <pre><code>def embed_query(query: str, embedding_config: EmbeddingConfig = config.default_embedding_config) -&gt; list[float]:\n    \"\"\"Embed a query string into a vector representation.\"\"\"\n    embedder = get_embedder(embedding_config)\n    return embedder.embed(text=query, text_type=TextType.QUERY)[0]\n</code></pre>"},{"location":"reference/embedding/#bear.embedding.embed_resources","title":"<code>embed_resources(resources, batch_size=256, embedding_config=config.default_embedding_config, embedding_field='embedding')</code>","text":"<p>Embed a list of resources in batch.</p> Source code in <code>bear/embedding.py</code> <pre><code>def embed_resources(\n    resources: list[ResourceType],\n    batch_size: int = 256,\n    embedding_config: EmbeddingConfig = config.default_embedding_config,\n    embedding_field: str = \"embedding\",\n) -&gt; list[ResourceType]:\n    \"\"\"Embed a list of resources in batch.\"\"\"\n\n    embedder = get_embedder(embedding_config)\n    logger.info(f\"Using embedder: {embedder.info}\")\n    for i in range(0, len(resources), batch_size):\n        logger.info(f\"Embedding resources {i} to {i + batch_size}\")\n        batch = resources[i : i + batch_size]\n        embeddings = embedder.embed(text=[str(resource) for resource in batch], text_type=TextType.DOC)\n        for resource, embedding in zip(batch, embeddings):\n            setattr(resource, embedding_field, embedding)\n    return resources\n</code></pre>"},{"location":"reference/embedding/#embedding-generation","title":"Embedding Generation","text":"<p>The embedding module handles text vectorization using OpenAI's embedding models.</p>"},{"location":"reference/embedding/#features","title":"Features","text":"<ul> <li>OpenAI API integration</li> <li>Batch processing</li> <li>Error handling and retries</li> <li>Multiple embedding model support</li> </ul>"},{"location":"reference/embedding/#supported-models","title":"Supported Models","text":"<ul> <li>text-embedding-3-large (default)</li> <li>text-embedding-3-small</li> <li>text-embedding-ada-002</li> </ul>"},{"location":"reference/embedding/#usage","title":"Usage","text":"<p>Embeddings are automatically generated during the ingestion process.</p>"},{"location":"reference/ingest/","title":"Ingest Reference","text":""},{"location":"reference/ingest/#bear.ingest","title":"<code>bear.ingest</code>","text":""},{"location":"reference/ingest/#bear.ingest.ingest","title":"<code>ingest(path, remove_ingested=False)</code>","text":"<p>Ingest staging file into Milvus.</p> Source code in <code>bear/ingest.py</code> <pre><code>def ingest(path: Path, remove_ingested: bool = False) -&gt; None:\n    \"\"\"Ingest staging file into Milvus.\"\"\"\n\n    logger.info(f\"Loading data from {path}\")\n    df = pd.read_parquet(path)\n\n    logger.info(f\"Data loaded with {len(df)} rows.\")\n    works = [Work.from_raw(row.to_dict()) for _, row in df.iterrows()]\n\n    works = embed_resources(works)\n    push(works)\n    logger.info(f\"Ingested {len(works)} works from {path} into Milvus.\")\n\n    if remove_ingested:\n        logger.info(f\"Removing file {path} after ingestion.\")\n        path.unlink()\n</code></pre>"},{"location":"reference/ingest/#bear.ingest.main","title":"<code>main()</code>","text":"<p>Main function to run the ingestion.</p> Source code in <code>bear/ingest.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main function to run the ingestion.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Ingest OpenAlex data into Milvus.\")\n    parser.add_argument(\"--path\", type=str, default=\"tmp/openalex_data/works\", help=\"Path to the directory containing parquet files to ingest.\")\n    parser.add_argument(\"--test\", action=\"store_true\", help=\"Run in test mode, ingest 10 files.\")\n\n    args = parser.parse_args()\n    staging_dir = Path(args.path)\n    files = list(staging_dir.rglob(\"*.parquet\"))\n    files = files[:10] if args.test else files\n\n    for file in files:\n        ingest(file, remove_ingested=True)\n    logger.info(f\"Ingestion complete for directory: {staging_dir}\")\n</code></pre>"},{"location":"reference/ingest/#data-ingestion-pipeline","title":"Data Ingestion Pipeline","text":"<p>The ingest module processes crawled data and loads it into the vector database.</p>"},{"location":"reference/ingest/#features","title":"Features","text":"<ul> <li>Parquet file processing</li> <li>Embedding generation</li> <li>Vector database insertion</li> <li>Batch processing</li> <li>Progress tracking</li> </ul>"},{"location":"reference/ingest/#usage","title":"Usage","text":"<pre><code># Test ingestion\nuv run bear/ingest.py --test\n\n# Full ingestion\nuv run bear/ingest.py\n</code></pre>"},{"location":"reference/ingest/#process-flow","title":"Process Flow","text":"<ol> <li>Load parquet files from crawler output</li> <li>Process and clean text data</li> <li>Generate embeddings</li> <li>Insert into Milvus vector database</li> <li>Create searchable indexes</li> </ol>"},{"location":"reference/model/","title":"Model Reference","text":""},{"location":"reference/model/#bear.model","title":"<code>bear.model</code>","text":""},{"location":"reference/model/#bear.model.Resource","title":"<code>Resource</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for resources that can be stored in Milvus.</p> Source code in <code>bear/model.py</code> <pre><code>class Resource(Protocol):\n    \"\"\"Protocol for resources that can be stored in Milvus.\"\"\"\n\n    @property\n    def _name(self) -&gt; str: ...  # Name of the resource for Milvus collection\n    @classmethod\n    def embedding_config(cls) -&gt; EmbeddingConfig: ...  # Embedding configuration for the resource\n    @staticmethod\n    def parse(raw_data: dict) -&gt; dict: ...  # Parse raw data to a dictionary suitable for the resource\n    @classmethod\n    def from_raw(cls, raw_data: dict) -&gt; Self: ...  # Create an instance from raw data\n    def to_milvus(self) -&gt; dict: ...  # Convert the resource to a dictionary for Milvus insertion\n    def __str__(self) -&gt; str: ...  # Return a string representation of the resource, used for embeddings.\n</code></pre>"},{"location":"reference/model/#bear.model.Work","title":"<code>Work</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Work from OpenAlex.</p> <p>This model use <code>pydantic</code> to validate the data before inserting into Milvus. It also store the Milvus collection schema for collection instantiation. Each the dictionary inside <code>WithJsonSchema</code> is a <code>pymilvus.FieldSchema.to_dict()</code> used for instantiating the Milvus collection.</p> Example <pre><code>from bear.model import Work\nfrom pymilvus import FieldSchema, DataType\n\ntitle_schema = FieldSchema(name=\"title\", datatype=DataType.VARCHAR, max_length=2048)\nclass NewCollectionName(BaseModel):\n\n    # Put Milvus `FieldSchema` inside `WithJsonSchema`.\n    # WithJsonSchema data can be access with `.model_fields[\"field_name\"].metadata[0].json_schema`\n    id: Annotated[int, WithJsonSchema({\"datatype\": DataType.INT64, \"is_primary\": True})]  # Easier to use\n    title: Annotated[str, WithJsonSchema(title_schema.to_dict())]  # Safer to use\n    ...\n</code></pre> Source code in <code>bear/model.py</code> <pre><code>class Work(BaseModel):\n    \"\"\"Work from OpenAlex.\n\n    This model use `pydantic` to validate the data before inserting into Milvus. It also store the Milvus collection schema for collection instantiation. Each the dictionary inside `WithJsonSchema` is a `pymilvus.FieldSchema.to_dict()` used for instantiating the Milvus collection.\n\n    Example:\n        ```python\n        from bear.model import Work\n        from pymilvus import FieldSchema, DataType\n\n        title_schema = FieldSchema(name=\"title\", datatype=DataType.VARCHAR, max_length=2048)\n        class NewCollectionName(BaseModel):\n\n            # Put Milvus `FieldSchema` inside `WithJsonSchema`.\n            # WithJsonSchema data can be access with `.model_fields[\"field_name\"].metadata[0].json_schema`\n            id: Annotated[int, WithJsonSchema({\"datatype\": DataType.INT64, \"is_primary\": True})]  # Easier to use\n            title: Annotated[str, WithJsonSchema(title_schema.to_dict())]  # Safer to use\n            ...\n        ```\n\n    \"\"\"\n\n    # OpenAlex Works fields\n    id: Annotated[str, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"is_primary\": True, \"max_length\": 64, \"index_configs\": {\"index_type\": \"AUTOINDEX\"}})]\n    doi: Annotated[\n        str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 256, \"index_configs\": {\"index_type\": \"AUTOINDEX\"}, \"nullable\": True})\n    ]\n    title: Annotated[str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 2048, \"nullable\": True})]\n    display_name: Annotated[str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 2048, \"nullable\": True})]\n    publication_year: Annotated[int | None, WithJsonSchema({\"datatype\": DataType.INT64, \"nullable\": True})]\n    publication_date: Annotated[str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 32, \"nullable\": True})]\n    type: Annotated[str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 256, \"nullable\": True})]\n    cited_by_count: Annotated[int | None, WithJsonSchema({\"datatype\": DataType.INT64, \"nullable\": True})]\n    is_retracted: Annotated[bool | None, WithJsonSchema({\"datatype\": DataType.BOOL, \"nullable\": True})]\n    is_paratext: Annotated[bool | None, WithJsonSchema({\"datatype\": DataType.BOOL, \"nullable\": True})]\n    cited_by_api_url: Annotated[str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 2048, \"nullable\": True})]\n    abstract_inverted_index: Annotated[dict[str, list[int]], Field(default_factory=dict), WithJsonSchema({\"datatype\": DataType.JSON})]\n\n    # Additional field via default works API\n    source_id: Annotated[str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 512, \"nullable\": True})]\n    source_display_name: Annotated[str | None, WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 512, \"nullable\": True})]\n    topics: Annotated[list[str], Field(default_factory=list), WithJsonSchema({\"datatype\": DataType.JSON})]\n    is_oa: Annotated[bool | None, Field(default=None), WithJsonSchema({\"datatype\": DataType.BOOL, \"nullable\": True})]\n    pdf_url: Annotated[str | None, Field(default=None), WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 2048, \"nullable\": True})]\n    landing_page_url: Annotated[str | None, Field(default=None), WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 2048, \"nullable\": True})]\n\n    # Denormalized authors (Milvus does not support nested objects)\n    author_ids: Annotated[\n        list[str | None],\n        Field(default_factory=list),\n        WithJsonSchema({\"datatype\": DataType.ARRAY, \"element_type\": DataType.VARCHAR, \"max_capacity\": 2048, \"nullable\": True, \"max_length\": 64}),\n    ]\n\n    embedding: Annotated[\n        list[float | None],\n        Field(default_factory=list),\n        WithJsonSchema(\n            {\n                \"datatype\": DataType.FLOAT_VECTOR,\n                \"dim\": config.default_embedding_config.dimensions,\n                \"index_configs\": config.default_embedding_config.index_config,\n            }\n        ),\n    ]\n\n    # Misc\n    ignore: Annotated[bool, Field(default=False), WithJsonSchema({\"datatype\": DataType.BOOL})]\n    last_modified: Annotated[\n        str, Field(default_factory=lambda: datetime.now().strftime(\"%Y-%m-%d\")), WithJsonSchema({\"datatype\": DataType.VARCHAR, \"max_length\": 32})\n    ]\n\n    @property\n    def _name(self) -&gt; str:\n        \"\"\"Return the name of the model for Milvus collection.\"\"\"\n        return self.__class__.__name__.lower()\n\n    @classmethod\n    def embedding_config(cls) -&gt; EmbeddingConfig:\n        \"\"\"Return the embedding configuration for the model.\"\"\"\n        return config.default_embedding_config\n\n    @property\n    def abstract(self) -&gt; str:\n        \"\"\"Recover the abstract from the inverted index.\"\"\"\n        return self._recover_abstract(self.abstract_inverted_index)\n\n    @staticmethod\n    def _recover_abstract(inverted_index: dict[str, list[int]]) -&gt; str:\n        \"\"\"Recover the abstract from the inverted index.\"\"\"\n        if not inverted_index:\n            return \"\"\n        word_positions = [(pos, word) for word, positions in inverted_index.items() if positions for pos in positions]\n        word_positions.sort()\n        return \" \".join(word for _, word in word_positions)\n\n    @staticmethod\n    def parse(raw_data: dict) -&gt; dict:\n        \"\"\"Parse a work from OpenAlex raw data to local Work format.\"\"\"\n\n        primary_location = raw_data.get(\"primary_location\", {}) or {}\n        source = primary_location.get(\"source\", {}) or {}\n        best_oa_location = raw_data.get(\"best_oa_location\", {}) or {}\n        authorships = raw_data.get(\"authorships\", [])\n\n        return {\n            \"id\": raw_data.get(\"id\"),\n            \"doi\": raw_data.get(\"doi\"),\n            \"title\": raw_data.get(\"title\"),\n            \"display_name\": raw_data.get(\"display_name\"),\n            \"publication_year\": raw_data.get(\"publication_year\"),\n            \"publication_date\": raw_data.get(\"publication_date\"),\n            \"type\": raw_data.get(\"type\"),\n            \"cited_by_count\": raw_data.get(\"cited_by_count\"),\n            \"is_retracted\": raw_data.get(\"is_retracted\"),\n            \"is_paratext\": raw_data.get(\"is_paratext\"),\n            \"cited_by_api_url\": raw_data.get(\"cited_by_api_url\"),\n            \"abstract_inverted_index\": _clean_inverted_index(raw_data.get(\"abstract_inverted_index\", {})),\n            \"source_id\": source.get(\"id\"),\n            \"source_display_name\": source.get(\"display_name\"),\n            \"topics\": [topic.get(\"display_name\") for topic in raw_data.get(\"topics\", [])],\n            \"is_oa\": best_oa_location.get(\"is_oa\", False),\n            \"pdf_url\": best_oa_location.get(\"pdf_url\"),\n            \"landing_page_url\": best_oa_location.get(\"landing_page_url\"),\n            \"author_ids\": [authorship.get(\"author\", {}).get(\"id\") for authorship in authorships],\n        }\n\n    @classmethod\n    def pull(cls, doi: str) -&gt; Self:\n        \"\"\"Pull a work from the OpenAlex by DOI.\"\"\"\n        response = httpx.get(f\"https://api.openalex.org/works/doi:{doi}\")\n        response.raise_for_status()\n        data = response.json()\n        return cls(**cls.parse(data))\n\n    @classmethod\n    def from_raw(cls, raw_data: dict) -&gt; Self:\n        \"\"\"Create a Work from raw data.\"\"\"\n        return cls(**cls.parse(raw_data))\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the work.\"\"\"\n        text = \"\"\n        if self.title:\n            text += f\"title: {self.title}\"\n        if self.source_display_name:\n            text += f\"\\njournal:{self.source_display_name}\"\n        if self.topics:\n            text += f\"\\ntopics: {', '.join(self.topics)}\"\n        if self.abstract:\n            text += f\"\\nabstract: {self.abstract}\"\n        return text\n\n    def to_milvus(self) -&gt; dict:\n        \"\"\"Convert to dictionary for Milvus insertion.\"\"\"\n        return self.model_dump()\n</code></pre>"},{"location":"reference/model/#bear.model.Work.abstract","title":"<code>abstract</code>  <code>property</code>","text":"<p>Recover the abstract from the inverted index.</p>"},{"location":"reference/model/#bear.model.Work.embedding_config","title":"<code>embedding_config()</code>  <code>classmethod</code>","text":"<p>Return the embedding configuration for the model.</p> Source code in <code>bear/model.py</code> <pre><code>@classmethod\ndef embedding_config(cls) -&gt; EmbeddingConfig:\n    \"\"\"Return the embedding configuration for the model.\"\"\"\n    return config.default_embedding_config\n</code></pre>"},{"location":"reference/model/#bear.model.Work.parse","title":"<code>parse(raw_data)</code>  <code>staticmethod</code>","text":"<p>Parse a work from OpenAlex raw data to local Work format.</p> Source code in <code>bear/model.py</code> <pre><code>@staticmethod\ndef parse(raw_data: dict) -&gt; dict:\n    \"\"\"Parse a work from OpenAlex raw data to local Work format.\"\"\"\n\n    primary_location = raw_data.get(\"primary_location\", {}) or {}\n    source = primary_location.get(\"source\", {}) or {}\n    best_oa_location = raw_data.get(\"best_oa_location\", {}) or {}\n    authorships = raw_data.get(\"authorships\", [])\n\n    return {\n        \"id\": raw_data.get(\"id\"),\n        \"doi\": raw_data.get(\"doi\"),\n        \"title\": raw_data.get(\"title\"),\n        \"display_name\": raw_data.get(\"display_name\"),\n        \"publication_year\": raw_data.get(\"publication_year\"),\n        \"publication_date\": raw_data.get(\"publication_date\"),\n        \"type\": raw_data.get(\"type\"),\n        \"cited_by_count\": raw_data.get(\"cited_by_count\"),\n        \"is_retracted\": raw_data.get(\"is_retracted\"),\n        \"is_paratext\": raw_data.get(\"is_paratext\"),\n        \"cited_by_api_url\": raw_data.get(\"cited_by_api_url\"),\n        \"abstract_inverted_index\": _clean_inverted_index(raw_data.get(\"abstract_inverted_index\", {})),\n        \"source_id\": source.get(\"id\"),\n        \"source_display_name\": source.get(\"display_name\"),\n        \"topics\": [topic.get(\"display_name\") for topic in raw_data.get(\"topics\", [])],\n        \"is_oa\": best_oa_location.get(\"is_oa\", False),\n        \"pdf_url\": best_oa_location.get(\"pdf_url\"),\n        \"landing_page_url\": best_oa_location.get(\"landing_page_url\"),\n        \"author_ids\": [authorship.get(\"author\", {}).get(\"id\") for authorship in authorships],\n    }\n</code></pre>"},{"location":"reference/model/#bear.model.Work.pull","title":"<code>pull(doi)</code>  <code>classmethod</code>","text":"<p>Pull a work from the OpenAlex by DOI.</p> Source code in <code>bear/model.py</code> <pre><code>@classmethod\ndef pull(cls, doi: str) -&gt; Self:\n    \"\"\"Pull a work from the OpenAlex by DOI.\"\"\"\n    response = httpx.get(f\"https://api.openalex.org/works/doi:{doi}\")\n    response.raise_for_status()\n    data = response.json()\n    return cls(**cls.parse(data))\n</code></pre>"},{"location":"reference/model/#bear.model.Work.from_raw","title":"<code>from_raw(raw_data)</code>  <code>classmethod</code>","text":"<p>Create a Work from raw data.</p> Source code in <code>bear/model.py</code> <pre><code>@classmethod\ndef from_raw(cls, raw_data: dict) -&gt; Self:\n    \"\"\"Create a Work from raw data.\"\"\"\n    return cls(**cls.parse(raw_data))\n</code></pre>"},{"location":"reference/model/#bear.model.Work.to_milvus","title":"<code>to_milvus()</code>","text":"<p>Convert to dictionary for Milvus insertion.</p> Source code in <code>bear/model.py</code> <pre><code>def to_milvus(self) -&gt; dict:\n    \"\"\"Convert to dictionary for Milvus insertion.\"\"\"\n    return self.model_dump()\n</code></pre>"},{"location":"reference/model/#data-models","title":"Data Models","text":"<p>The model module defines data structures and schemas used throughout BEAR.</p>"},{"location":"reference/model/#features","title":"Features","text":"<ul> <li>Pydantic model definitions</li> <li>Data validation</li> <li>Type checking</li> <li>Serialization/deserialization</li> </ul>"},{"location":"reference/model/#models","title":"Models","text":""},{"location":"reference/model/#work","title":"Work","text":"<p>Represents an academic work/publication.</p>"},{"location":"reference/model/#author","title":"Author","text":"<p>Represents an academic author.</p>"},{"location":"reference/model/#institution","title":"Institution","text":"<p>Represents an academic institution.</p>"},{"location":"reference/search/","title":"Search Reference","text":""},{"location":"reference/search/#bear.search","title":"<code>bear.search</code>","text":""},{"location":"reference/search/#bear.search.SearchEngine","title":"<code>SearchEngine</code>","text":"<p>Search engine for vector-based similarity search across resources.</p> Source code in <code>bear/search.py</code> <pre><code>class SearchEngine:\n    \"\"\"Search engine for vector-based similarity search across resources.\"\"\"\n\n    def __init__(self, client=None):\n        self.client = client or get_milvus_client()\n\n    def search_resource(\n        self,\n        resource_name: str,\n        query: str,\n        top_k: int = 3,\n        min_distance: float | None = None,\n        since_year: int | None = None,\n        author_ids: list[str] | None = None,\n        output_fields: list[str] | None = None,\n    ) -&gt; list[dict[str, Any]]:\n        \"\"\"Search and filter for resource using a query.\n\n        Args:\n            resource_name: Name of the resource collection to search\n            query: Search query string\n            top_k: Maximum number of results to return\n            min_distance: Minimum distance threshold for results\n            since_year: Filter results from this year onwards\n            author_ids: Filter results by specific author IDs\n            output_fields: Fields to include in output. If None, all fields except embedding\n\n        Returns:\n            List of search results sorted by distance (descending)\n\n        Raises:\n            ValueError: If resource class is not found in model\n        \"\"\"\n        # Build filter conditions\n        filter_conditions = [\"ignore == false\"]\n        if since_year is not None:\n            filter_conditions.append(f\"publication_year &gt;= {since_year}\")\n        if author_ids is not None:\n            filter_conditions.append(f\"array_contains_any(author_ids, {author_ids})\")\n        filter_expr = \" and \".join(filter_conditions)\n\n        # Get resource class and validate\n        resource_class = getattr(model, resource_name.capitalize(), None)\n        if not resource_class:\n            raise ValueError(f\"Resource class '{resource_name}' not found in model.\")\n\n        # Set output fields if not provided\n        if output_fields is None:\n            output_fields = [field for field in resource_class.model_fields.keys() if field != \"embedding\"]\n\n        # Prepare search arguments\n        search_args = {\n            \"collection_name\": resource_name,\n            \"data\": [embed_query(query)],\n            \"limit\": top_k,\n            \"output_fields\": output_fields,\n            \"filter\": filter_expr,\n        }\n\n        # Execute search\n        results = self.client.search(**search_args)[0]\n\n        # Apply distance filter if specified\n        if min_distance is not None:\n            results = [result for result in results if result[\"distance\"] &gt; min_distance]\n\n        return sorted(results, key=lambda x: x[\"distance\"], reverse=True)\n\n    def search_author(self, query: str, top_k: int = 3, aggregate_function: Callable = sum, institutions: list[str] | None = None, **kwargs) -&gt; list[dict]:\n        \"\"\"Search for authors based on a query string.\"\"\"\n        resources = self.search_resource(\"work\", query, top_k, **kwargs)\n        results = rerank_by_author(resources, aggregate_function=aggregate_function)  # this must be done before filtering\n        if institutions:\n            results = filter_institution_authors(institutions=institutions, results=results)\n        return results\n</code></pre>"},{"location":"reference/search/#bear.search.SearchEngine.search_resource","title":"<code>search_resource(resource_name, query, top_k=3, min_distance=None, since_year=None, author_ids=None, output_fields=None)</code>","text":"<p>Search and filter for resource using a query.</p> <p>Parameters:</p> Name Type Description Default <code>resource_name</code> <code>str</code> <p>Name of the resource collection to search</p> required <code>query</code> <code>str</code> <p>Search query string</p> required <code>top_k</code> <code>int</code> <p>Maximum number of results to return</p> <code>3</code> <code>min_distance</code> <code>float | None</code> <p>Minimum distance threshold for results</p> <code>None</code> <code>since_year</code> <code>int | None</code> <p>Filter results from this year onwards</p> <code>None</code> <code>author_ids</code> <code>list[str] | None</code> <p>Filter results by specific author IDs</p> <code>None</code> <code>output_fields</code> <code>list[str] | None</code> <p>Fields to include in output. If None, all fields except embedding</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>List of search results sorted by distance (descending)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If resource class is not found in model</p> Source code in <code>bear/search.py</code> <pre><code>def search_resource(\n    self,\n    resource_name: str,\n    query: str,\n    top_k: int = 3,\n    min_distance: float | None = None,\n    since_year: int | None = None,\n    author_ids: list[str] | None = None,\n    output_fields: list[str] | None = None,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"Search and filter for resource using a query.\n\n    Args:\n        resource_name: Name of the resource collection to search\n        query: Search query string\n        top_k: Maximum number of results to return\n        min_distance: Minimum distance threshold for results\n        since_year: Filter results from this year onwards\n        author_ids: Filter results by specific author IDs\n        output_fields: Fields to include in output. If None, all fields except embedding\n\n    Returns:\n        List of search results sorted by distance (descending)\n\n    Raises:\n        ValueError: If resource class is not found in model\n    \"\"\"\n    # Build filter conditions\n    filter_conditions = [\"ignore == false\"]\n    if since_year is not None:\n        filter_conditions.append(f\"publication_year &gt;= {since_year}\")\n    if author_ids is not None:\n        filter_conditions.append(f\"array_contains_any(author_ids, {author_ids})\")\n    filter_expr = \" and \".join(filter_conditions)\n\n    # Get resource class and validate\n    resource_class = getattr(model, resource_name.capitalize(), None)\n    if not resource_class:\n        raise ValueError(f\"Resource class '{resource_name}' not found in model.\")\n\n    # Set output fields if not provided\n    if output_fields is None:\n        output_fields = [field for field in resource_class.model_fields.keys() if field != \"embedding\"]\n\n    # Prepare search arguments\n    search_args = {\n        \"collection_name\": resource_name,\n        \"data\": [embed_query(query)],\n        \"limit\": top_k,\n        \"output_fields\": output_fields,\n        \"filter\": filter_expr,\n    }\n\n    # Execute search\n    results = self.client.search(**search_args)[0]\n\n    # Apply distance filter if specified\n    if min_distance is not None:\n        results = [result for result in results if result[\"distance\"] &gt; min_distance]\n\n    return sorted(results, key=lambda x: x[\"distance\"], reverse=True)\n</code></pre>"},{"location":"reference/search/#bear.search.SearchEngine.search_author","title":"<code>search_author(query, top_k=3, aggregate_function=sum, institutions=None, **kwargs)</code>","text":"<p>Search for authors based on a query string.</p> Source code in <code>bear/search.py</code> <pre><code>def search_author(self, query: str, top_k: int = 3, aggregate_function: Callable = sum, institutions: list[str] | None = None, **kwargs) -&gt; list[dict]:\n    \"\"\"Search for authors based on a query string.\"\"\"\n    resources = self.search_resource(\"work\", query, top_k, **kwargs)\n    results = rerank_by_author(resources, aggregate_function=aggregate_function)  # this must be done before filtering\n    if institutions:\n        results = filter_institution_authors(institutions=institutions, results=results)\n    return results\n</code></pre>"},{"location":"reference/search/#bear.search.rerank_by_author","title":"<code>rerank_by_author(results, aggregate_function=sum)</code>","text":"<p>Rerank the search results by author ID.</p> Source code in <code>bear/search.py</code> <pre><code>def rerank_by_author(results: list[dict[str, Any]], aggregate_function: Callable = sum) -&gt; list[dict[str, float]]:\n    \"\"\"Rerank the search results by author ID.\"\"\"\n    result = defaultdict(list)\n    for r in results:\n        for author_id in r[\"author_ids\"]:\n            result[author_id].append(r[\"distance\"])\n\n    # Calculate author scores with aggregate function\n    result = dict(result)\n    author_scores = {author_id: aggregate_function(distances) for author_id, distances in result.items()}\n\n    # Sort authors by score\n    sorted_authors = sorted(author_scores.items(), key=lambda x: x[1], reverse=True)\n    return [{\"author_id\": author_id, \"score\": score} for author_id, score in sorted_authors]\n</code></pre>"},{"location":"reference/search/#bear.search.load_institution_author_ids","title":"<code>load_institution_author_ids(institution)</code>  <code>cached</code>","text":"<p>Load author IDs associated with a specific institution.</p> Source code in <code>bear/search.py</code> <pre><code>@cache\ndef load_institution_author_ids(institution: str) -&gt; set[str]:\n    \"\"\"Load author IDs associated with a specific institution.\"\"\"\n\n    assert institution in INSTITUTION_AUTHOR_DIRECTORY, \"Institution not found in directory map.\"\n    df = pd.read_parquet(INSTITUTION_AUTHOR_DIRECTORY[institution], columns=[\"id\"])\n    logger.info(f\"Loaded {len(df)} author IDs for institution: {institution}\")\n    return set(df[\"id\"].values)\n</code></pre>"},{"location":"reference/search/#bear.search.filter_institution_authors","title":"<code>filter_institution_authors(institutions, results)</code>","text":"<p>Filter authors by institution.</p> Source code in <code>bear/search.py</code> <pre><code>def filter_institution_authors(institutions: list[str], results: list[dict[str, Any]]) -&gt; list[dict[str, Any]]:\n    \"\"\"Filter authors by institution.\"\"\"\n\n    logger.info(f\"Filtering authors for institutions: {institutions}\")\n    logger.info(f\"Total results before filtering: {len(results)}\")\n    acceptable_author_ids = set()\n    for institution in institutions:\n        assert institution in INSTITUTION_AUTHOR_DIRECTORY, \"Institution not found in directory map.\"\n        acceptable_author_ids.update(load_institution_author_ids(institution))\n    filtered_results = [result for result in results if result[\"author_id\"] in acceptable_author_ids]\n    logger.info(f\"Total results after filtering: {len(filtered_results)}\")\n    return filtered_results\n</code></pre>"},{"location":"reference/search/#search-engine","title":"Search Engine","text":"<p>The search module provides vector search capabilities for academic resources.</p>"},{"location":"reference/search/#features","title":"Features","text":"<ul> <li>Vector similarity search</li> <li>Metadata filtering</li> <li>Result ranking</li> <li>Multi-modal search (authors and works)</li> </ul>"},{"location":"reference/search/#search-types","title":"Search Types","text":""},{"location":"reference/search/#resource-search","title":"Resource Search","text":"<p>Search for academic works, papers, and publications.</p>"},{"location":"reference/search/#author-search","title":"Author Search","text":"<p>Search for authors based on research interests and expertise.</p>"},{"location":"reference/search/#filtering-options","title":"Filtering Options","text":"<ul> <li>Publication year filtering</li> <li>Institution filtering</li> <li>Citation count filtering</li> <li>Distance threshold filtering</li> </ul>"},{"location":"reference/search/#performance","title":"Performance","text":"<p>The search engine is optimized for:</p> <ul> <li>Sub-second query response times</li> <li>Accurate semantic matching</li> <li>Scalable to millions of documents</li> </ul>"}]}